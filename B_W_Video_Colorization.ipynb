{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B W Video Colorization\n",
    "**Based on \"Black and white image colorization with OpenCV and Deep Learning\", by Dr. Adrian Rosebrok:**<br>\n",
    "https://www.pyimagesearch.com/2019/02/25/black-and-white-image-colorization-with-opencv-and-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Page to Download videos from a URL:**<br>\n",
    "https://www.vidpaw.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T21:11:40.626663Z",
     "start_time": "2019-02-28T21:11:40.356811Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T21:11:41.469064Z",
     "start_time": "2019-02-28T21:11:41.466880Z"
    }
   },
   "outputs": [],
   "source": [
    "VIDEO = \"rio_32.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T14:45:53.314182Z",
     "start_time": "2019-03-01T14:45:53.304779Z"
    }
   },
   "outputs": [],
   "source": [
    "# define paths\n",
    "prototxt = \"./model/colorization_deploy_v2.prototxt\"\n",
    "model = \"./model/colorization_release_v2.caffemodel\"\n",
    "points = \"./model/pts_in_hull.npy\"\n",
    "video =  \"./input_video/\"+VIDEO\n",
    "width = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T21:11:42.886701Z",
     "start_time": "2019-02-28T21:11:42.872697Z"
    }
   },
   "outputs": [],
   "source": [
    "vs = cv2.VideoCapture(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T21:11:44.019619Z",
     "start_time": "2019-02-28T21:11:43.626657Z"
    }
   },
   "outputs": [],
   "source": [
    "# load our serialized black and white colorizer model and cluster\n",
    "# center points from disk\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt,model)\n",
    "pts = np.load(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T21:11:44.307565Z",
     "start_time": "2019-02-28T21:11:44.303192Z"
    }
   },
   "outputs": [],
   "source": [
    "# add the cluster centers as 1x1 convolutions to the model\n",
    "class8 = net.getLayerId(\"class8_ab\")\n",
    "conv8 = net.getLayerId(\"conv8_313_rh\")\n",
    "pts = pts.transpose().reshape(2, 313, 1, 1)\n",
    "net.getLayer(class8).blobs = [pts.astype(\"float32\")]\n",
    "net.getLayer(conv8).blobs = [np.full([1, 313], 2.606, dtype=\"float32\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:21:57.201564Z",
     "start_time": "2019-02-28T21:11:46.105962Z"
    }
   },
   "outputs": [],
   "source": [
    "# loop over frames from the video stream\n",
    "count = 0\n",
    "success = True\n",
    "while success:\n",
    "\t# grab the next frame and handle if we are reading from either\n",
    "\t# VideoCapture or VideoStream\n",
    "\tsuccess, frame = vs.read()\n",
    "\n",
    "\t# if we are viewing a video and we did not grab a frame then we\n",
    "\t# have reached the end of the video\n",
    "\tif frame is None:\n",
    "\t\tbreak\n",
    "\n",
    "\t# resize the input frame, scale the pixel intensities to the\n",
    "\t# range [0, 1], and then convert the frame from the BGR to Lab\n",
    "\t# color space\n",
    "\tframe = imutils.resize(frame, 500)\n",
    "\tframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\tframe = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "\tscaled = frame.astype(\"float32\") / 255.0\n",
    "\tlab = cv2.cvtColor(scaled, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "\t# resize the Lab frame to 224x224 (the dimensions the colorization\n",
    "\t# network accepts), split channels, extract the 'L' channel, and\n",
    "\t# then perform mean centering\n",
    "\tresized = cv2.resize(lab, (224, 224))\n",
    "\tL = cv2.split(resized)[0]\n",
    "\tL -= 50\n",
    "\n",
    "\t# pass the L channel through the network which will *predict* the\n",
    "\t# 'a' and 'b' channel values\n",
    "\tnet.setInput(cv2.dnn.blobFromImage(L))\n",
    "\tab = net.forward()[0, :, :, :].transpose((1, 2, 0))\n",
    "\n",
    "\t# resize the predicted 'ab' volume to the same dimensions as our\n",
    "\t# input frame, then grab the 'L' channel from the *original* input\n",
    "\t# frame (not the resized one) and concatenate the original 'L'\n",
    "\t# channel with the predicted 'ab' channels\n",
    "\tab = cv2.resize(ab, (frame.shape[1], frame.shape[0]))\n",
    "\tL = cv2.split(lab)[0]\n",
    "\tcolorized = np.concatenate((L[:, :, np.newaxis], ab), axis=2)\n",
    "\n",
    "\t# convert the output frame from the Lab color space to RGB, clip\n",
    "\t# any values that fall outside the range [0, 1], and then convert\n",
    "\t# to an 8-bit unsigned integer ([0, 255] range)\n",
    "\tcolorized = cv2.cvtColor(colorized, cv2.COLOR_LAB2BGR)\n",
    "\tcolorized = np.clip(colorized, 0, 1)\n",
    "\tcolorized = (255 * colorized).astype(\"uint8\")\n",
    "\n",
    "\t# show the original and final colorized frames\n",
    "\tcv2.imshow(\"Original\", frame)\n",
    "\tcv2.imshow(\"Colorized\", colorized)\n",
    "    \n",
    "\tcv2.imwrite(\"./colorized_video_frames/frame%d.jpg\" % count, colorized)\n",
    "\tcount += 1\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\t# if the `q` key was pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "\n",
    "vs.release()\n",
    "\n",
    "# close any open windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T13:07:01.946157Z",
     "start_time": "2019-03-01T13:07:01.918797Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_frames_to_video(pathIn, pathOut, fps):\n",
    "    frame_array = []\n",
    "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    " \n",
    "    #for sorting the file names properly\n",
    "    files.sort(key = lambda x: int(x[5:-4]))\n",
    " \n",
    "    for i in range(len(files)):\n",
    "        filename=pathIn + files[i]\n",
    "        #reading each files\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        print(filename)\n",
    "        #inserting the frames into an image array\n",
    "        frame_array.append(img)\n",
    " \n",
    "    out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'MJPG'), fps, size)\n",
    " \n",
    "    for i in range(len(frame_array)):\n",
    "        # writing to a image array\n",
    "        out.write(frame_array[i])\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T13:07:04.540130Z",
     "start_time": "2019-03-01T13:07:04.306801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_W_Photo_Colorization.ipynb           \u001b[34mcolorized_video_frames\u001b[m\u001b[m/\r\n",
      "B_W_Photo_Colorization_function.ipynb  \u001b[34mcolorized_videos\u001b[m\u001b[m/\r\n",
      "B_W_Video_Colorization.ipynb           \u001b[34minput_images\u001b[m\u001b[m/\r\n",
      "Paper_Colorization.pdf                 \u001b[34minput_video\u001b[m\u001b[m/\r\n",
      "\u001b[34mbw-colorization\u001b[m\u001b[m/                       \u001b[34mresults\u001b[m\u001b[m/\r\n",
      "\u001b[34mcolorized_images\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T13:14:20.569886Z",
     "start_time": "2019-03-01T13:07:07.504777Z"
    }
   },
   "outputs": [],
   "source": [
    "pathIn= './colorized_video_frames/'\n",
    "pathOut = './colorized_videos/video.avi'\n",
    "fps = 30.0\n",
    "convert_frames_to_video(pathIn, pathOut, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
